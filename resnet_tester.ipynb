{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v11s를 이용한 개 객체 탐지 후 224x224로 리사이즈하고 모델 테스트\n",
    "욜로는 COCO 데이터셋의 80개의 클래스를 가지고 사전학습된 모델입니다.\n",
    "80개의 클래스 중에 16번 인덱스(숫자로 세면 17번쨰)이 개 클래스인데 출처에 따라 인덱스 17이라고 조금 다르게 나옵니다.\n",
    "일단 작동해서 16으로 두었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ YOLOv11 모델이 성공적으로 로드되었습니다!\n",
      "Using device: mps\n",
      "✅ ResNet모델이 성공적으로 로드되었습니다!\n",
      "\n",
      "0: 416x640 1 dog, 60.5ms\n",
      "Speed: 0.9ms preprocess, 60.5ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "🔍 검출된 객체들:\n",
      "  클래스: 16, 신뢰도: 0.95\n",
      "✅ 예측된 포즈: SIT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 모델, 욜로, 이미지 경로 수정만 해주시면 됩니다.\n",
    "# ------------------------\n",
    "# 1. YOLOv11 모델 로드 (개 객체 탐지용)\n",
    "# ------------------------\n",
    "# YOLOv11s 모델은 COCO 데이터셋으로 사전 학습되어 있으므로, 'dog' 클래스(일반적으로 클래스 인덱스 16)를 인식합니다.\n",
    "yolo_model_path = \"/Users/vairocana/Downloads/yolo11m.pt\"  # YOLOv11s 모델 파일 경로 (해당 파일이 존재해야 함)\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "print(\"✅ YOLOv11 모델이 성공적으로 로드되었습니다!\")\n",
    "\n",
    "# ------------------------\n",
    "# 2. ResNet 모델 로드 (분류용)\n",
    "# ------------------------\n",
    "model_path = \"/Users/vairocana/Desktop/AI/resnet_models/resnet18_model_82.pth\"  # 저장된 ResNet50 모델 파일 경로\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ResNet50 모델을 사전 학습된 가중치 없이 생성한 후, 마지막 fc 레이어를 데이터셋 클래스 수에 맞게 수정\n",
    "model = models.resnet18(weights=None)\n",
    "num_features = model.fc.in_features\n",
    "num_classes = 10  # 클래스 개수 (데이터셋에 맞게 수정)\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # 평가 모드로 전환 (Dropout, BatchNorm 등 비활성화)\n",
    "print(\"✅ ResNet모델이 성공적으로 로드되었습니다!\")\n",
    "\n",
    "# ------------------------\n",
    "# 3. 이미지 전처리 함수 정의 (224×224, 정규화)\n",
    "# ------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 크롭된 이미지를 224×224로 조정\n",
    "    transforms.ToTensor(),  # 텐서 변환\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet 정규화\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 4. YOLO를 이용하여 \"dog\" 객체를 탐지하고 크롭하는 함수\n",
    "# ------------------------\n",
    "def detect_and_crop(image_path):\n",
    "    \"\"\"\n",
    "    주어진 이미지 경로에서 YOLOv8을 이용해 'dog' 객체(클래스 인덱스 16)를 탐지하고,\n",
    "    해당 바운딩 박스 영역을 크롭한 후 224×224로 전처리한 이미지를 반환합니다.\n",
    "    \"\"\"\n",
    "    # 이미지 로드 및 BGR -> RGB 변환 (YOLO는 RGB 사용)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"❌ 이미지 로드 실패: {image_path}\")\n",
    "        return None\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # YOLO 추론 수행\n",
    "    results = yolo_model(image_rgb)\n",
    "\n",
    "    # 디버그: 탐지된 모든 객체 정보 출력\n",
    "    print(\"🔍 검출된 객체들:\")\n",
    "    for result in results:\n",
    "        for box in result.boxes.data:\n",
    "            # YOLOv11 결과 tensor를 리스트로 변환하여 [x1, y1, x2, y2, confidence, class] 순서로 얻음\n",
    "            box_vals = box.tolist()\n",
    "            x1, y1, x2, y2, conf, cls = box_vals\n",
    "            print(f\"  클래스: {int(cls)}, 신뢰도: {conf:.2f}\")\n",
    "\n",
    "    # 'dog' 객체 추출 (COCO 기준 dog 클래스 인덱스는 일반적으로 16)\n",
    "    found_dog = False\n",
    "    for result in results:\n",
    "        for box in result.boxes.data:\n",
    "            box_vals = box.tolist()\n",
    "            x1, y1, x2, y2, conf, cls = box_vals\n",
    "            # 여기서 dog 클래스 조건: 클래스 인덱스 16, 신뢰도 0.4 이상 (필요에 따라 조정)\n",
    "            if int(cls) == 16 and conf > 0.4:\n",
    "                found_dog = True\n",
    "                # 좌표 정수형 변환\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                # 개 객체 영역 크롭 (RGB 이미지 기준)\n",
    "                cropped_img = image_rgb[y1:y2, x1:x2]\n",
    "                # PIL 이미지로 변환\n",
    "                cropped_img_pil = Image.fromarray(cropped_img)\n",
    "                # 전처리: 224×224 리사이즈 및 정규화, 배치 차원 추가\n",
    "                processed_img = transform(cropped_img_pil)\n",
    "                processed_img = processed_img.unsqueeze(0)\n",
    "                return processed_img.to(device)\n",
    "    if not found_dog:\n",
    "        print(\"⚠️ 이미지에서 개 객체를 감지하지 못했습니다!\")\n",
    "    return None\n",
    "\n",
    "# ------------------------\n",
    "# 5. ResNet을 이용하여 포즈(클래스) 분류하는 함수\n",
    "# ------------------------\n",
    "def classify_pose(image_path):\n",
    "    \"\"\"\n",
    "    YOLO를 사용해 주어진 이미지에서 개 객체를 탐지하여 크롭한 후,\n",
    "    ResNet 모델로 분류하여 포즈(클래스)를 예측하는 함수.\n",
    "    \"\"\"\n",
    "    cropped_image = detect_and_crop(image_path)\n",
    "    if cropped_image is None:\n",
    "        print(\"❌ 예측을 수행할 개 이미지가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    # ResNet50을 이용한 예측 (gradient 계산 비활성화)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(cropped_image)\n",
    "        _, predicted_class = outputs.max(1)\n",
    "\n",
    "    # 클래스 라벨 (데이터셋에 맞게 수정)\n",
    "    class_labels = [\n",
    "        \"BODYLOWER\", \"BODYSCRATCH\", \"BODYSHAKE\", \"FEETUP\", \n",
    "        \"FOOTUP\", \"LYING\", \"MOUNTING\", \"SIT\", \"TURN\", \"WALKRUN\"\n",
    "    ]\n",
    "    predicted_label = class_labels[predicted_class.item()]\n",
    "    print(f\"✅ 예측된 포즈: {predicted_label}\")\n",
    "\n",
    "# ------------------------\n",
    "# 6. 실행: 단일 이미지에 대해 YOLO로 개 객체 탐지 후, ResNet으로 분류\n",
    "# ------------------------\n",
    "image_path = \"/Users/vairocana/Downloads/sample7.jpeg\"  # 테스트할 이미지 경로 (수정 필요)\n",
    "classify_pose(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 욜로로 크롭된 이미지 확인을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ YOLOv11 모델이 성공적으로 로드되었습니다!\n",
      "\n",
      "0: 640x512 2 dogs, 1 skis, 46.3ms\n",
      "Speed: 1.3ms preprocess, 46.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "🔍 검출된 객체들:\n",
      "  클래스: 16, 신뢰도: 0.81\n",
      "  클래스: 16, 신뢰도: 0.36\n",
      "  클래스: 30, 신뢰도: 0.33\n",
      "✅ 개 객체를 검출하여 크롭했습니다! 저장 경로: /Users/vairocana/Downloads//cropped_dog.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#욜로와 이미지 경로만 수정해주시면 됩니다.\n",
    "# ------------------------\n",
    "# 1. YOLOv11 모델 로드 \n",
    "# ------------------------\n",
    "yolo_model_path = \"/Users/vairocana/Downloads/yolo11s.pt\"  # YOLOv11s 모델 파일 경로 (해당 파일이 존재해야 함)\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "print(\"✅ YOLOv11 모델이 성공적으로 로드되었습니다!\")\n",
    "\n",
    "# ------------------------\n",
    "# 2. 이미지 경로 설정 (필요에 따라 수정)\n",
    "# ------------------------\n",
    "image_path = \"/Users/vairocana/Downloads/coco_sample2.jpg\"\n",
    "output_path = \"/Users/vairocana/Downloads//cropped_dog.jpg\"\n",
    "\n",
    "# ------------------------\n",
    "# 3. 이미지 로드 및 YOLO 추론 수행\n",
    "# ------------------------\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    print(f\"❌ 이미지 로드 실패: {image_path}\")\n",
    "    exit()\n",
    "\n",
    "# OpenCV는 BGR, YOLO는 RGB이므로 변환\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = yolo_model(image_rgb)  # YOLO 추론 수행\n",
    "\n",
    "# ------------------------\n",
    "# 4. 디버깅: 검출된 모든 객체 정보 출력\n",
    "# ------------------------\n",
    "print(\"🔍 검출된 객체들:\")\n",
    "for result in results:\n",
    "    # result.boxes.data는 각 박스에 대해 [x1, y1, x2, y2, confidence, class]를 포함하는 tensor입니다.\n",
    "    for box in result.boxes.data:\n",
    "        # 텐서를 리스트로 변환하여 인덱스로 접근\n",
    "        box = box.tolist()\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        print(f\"  클래스: {int(cls)}, 신뢰도: {conf:.2f}\")\n",
    "\n",
    "# ------------------------\n",
    "# 5. \"dog\" 클래스 (COCO 기준 dog의 클래스 인덱스는 16이라고 나온곳도 있고 17도 있음..)만 추출하여 크롭\n",
    "# ------------------------\n",
    "found_dog = False\n",
    "for result in results:\n",
    "    for box in result.boxes.data:\n",
    "        box = box.tolist()\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        if int(cls) == 16 and conf > 0.4:  # dog 클래스 인덱스가 16 아니면 17인데 찾아도 둘다 나와서 일단 16으로 설정. 조건 (신뢰도 0.4 이상)\n",
    "            found_dog = True\n",
    "            # 좌표 정수형 변환\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "            # 개 객체 영역 크롭 (RGB 이미지 기준)\n",
    "            cropped_dog = image_rgb[y1:y2, x1:x2]\n",
    "            # PIL 이미지로 변환 후 저장 (JPEG 품질 95)\n",
    "            cropped_img_pil = Image.fromarray(cropped_dog)\n",
    "            cropped_img_pil.save(output_path, quality=95)\n",
    "            print(f\"✅ 개 객체를 검출하여 크롭했습니다! 저장 경로: {output_path}\")\n",
    "            break  # 하나의 개만 처리\n",
    "    if found_dog:\n",
    "        break\n",
    "\n",
    "if not found_dog:\n",
    "    print(\"❌ 이미지에서 개 객체를 감지하지 못했습니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
